
# ğŸ”§ PhysAugNet

**PhysAugNet** is a research-grade Python toolkit designed to enhance **few-shot** or **low-data** industrial defect segmentation tasks by integrating:

- ğŸŒ **Vector-Quantized Variational Autoencoding (VQ-VAE)** for **generative reconstructions**
- ğŸ”¥ **Physically-inspired augmentations** including **thermal distortion** and **sensor grain noise**

This augmentation pipeline improves generalization and robustness of deep segmentation models in **industrial inspection** workflows.

---

## ğŸš€ Key Features

- âœ… **Compact and efficient VQ-VAE** architecture with fast convergence  
- âœ… Dual-mode augmentation: **thermal distortion** + **sensor grain noise**  
- âœ… **PhysAugNet Fusion**: Combines VQ-VAE reconstructions with physics-inspired augmentations  
- âœ… CLI-based experiment control via **YAML configuration**  
- âœ… Fully **modular** and easy to plug into PyTorch pipelines  
- âœ… Lightweight design tailored for **few-shot learning** and **resource-constrained environments**

---

## ğŸ§© Computational Pipeline

| Module                      | Operation       | Description                                                    |
|----------------------------|------------------|----------------------------------------------------------------|
| `physaug/vqvae/train.py`   | Training         | Trains VQ-VAE to learn latent quantized space                  |
| `physaug/vqvae/infer.py`   | Inference        | Reconstructs defect images for augmentation                    |
| `physaug/augment/thermal.py` | Augmentation   | Applies thermal distortion to images                           |
| `physaug/augment/grain.py`   | Augmentation   | Applies synthetic sensor grain noise                           |
| `physaug/augment/combined.py`| Augmentation   | Fuses VQ-VAE reconstructions with thermal + grain noise        |
| `infer_video.py`           | Video Inference  | Performs VQ-VAE reconstructions on video frames                |
| `main.py`                  | CLI Launcher     | Unified command-line interface with `argparse` routing         |
| `configs/default.yaml`     | Config           | Centralized configuration for all training and inference tasks |

---

## ğŸ—‚ Project Structure

```
PhysAugNet/
â”œâ”€â”€ physaug/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vqvae/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vqvae.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ infer.py
â”‚   â”œâ”€â”€ augment/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ thermal.py
â”‚   â”‚   â”œâ”€â”€ grain.py
â”‚   â”‚   â””â”€â”€ combined.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ io.py
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ notebook_demo.ipynb
â”œâ”€â”€ physaugnet.egg-info/
â”œâ”€â”€ main.py
â”œâ”€â”€ train_vqvae.py
â”œâ”€â”€ gen_vqvae.py
â”œâ”€â”€ augment_thermal.py
â”œâ”€â”€ augment_combined.py
â”œâ”€â”€ infer_video.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

### Option 1: Install from PyPI (Recommended)

```bash
pip install physaugnet
```

### Option 2: Clone the Repository

```bash
git clone https://github.com/Shantanu-Parmar/PhysAugNet
cd PhysAugNet
```

Create a virtual environment:
```bash
# Linux/Mac
python -m venv Physaug
source Physaug/bin/activate

# Windows
python -m venv Physaug
Physaug\Scripts\activate
```

Install dependencies:
```bash
pip install -r requirements.txt
```

Or install the package:
```bash
python setup.py install
```

---

## âš™ï¸ Setup

### ğŸ“ Dataset Preparation

- Place **training images** under:  
  `images/train/<class_name>/`
  
- Place **test images** under:  
  `images/test/`

### ğŸ“ Directory Creation

```bash
mkdir -p checkpoints/vqvae outputs/reconstructed outputs/augmented outputs/combined logs
```

### ğŸ›  Config File

Edit `configs/default.yaml` to ensure all paths and parameters are correctly set for your environment.

---

## ğŸ–¥ Usage

Run from the root `PhysAugNet/` directory using CLI:

### ğŸ”§ VQ-VAE Training

```bash
python -m physaug.main train_vqvae --config configs/default.yaml
```

### ğŸ§  Image Reconstruction (VQ-VAE)

```bash
python -m physaug.main reconstruct --config configs/default.yaml
```

### ğŸŒ¡ Thermal + Grain Augmentation

```bash
python -m physaug.main augment_tg --config configs/default.yaml
```

### ğŸ” Combined VQ-VAE + Physical Augmentations

```bash
python -m physaug.main augment_combined --config configs/default.yaml
```

### ğŸ Video Frame Reconstruction (VQ-VAE)

```bash
python infer_video.py   --video_path images/DEMO_INFERENCE.mp4   --output_path outputs/reconstructed_video.mp4   --checkpoint checkpoints/vqvae.pth   --config configs/default.yaml
```

---

## ğŸ““ Notebook Demonstration

Open the demo notebook to:

- Train the VQ-VAE
- Reconstruct images
- Apply augmentations
- Combine and visualize outputs

```bash
jupyter notebook examples/notebook_demo.ipynb
```

---

## ğŸ“¤ Output Structure

| Type                | Path                        |
|---------------------|-----------------------------|
| Logs                | `logs/` (e.g., `vqvae_trainer.log`) |
| Checkpoints         | `checkpoints/vqvae/`        |
| Reconstructed Images| `outputs/reconstructed/`    |
| Augmented Images    | `outputs/augmented/`        |
| Combined Outputs    | `outputs/combined/`         |
| Video Outputs       | `outputs/reconstructed_video.mp4` |

---

## ğŸ§ª Applications

- Few-shot segmentation in manufacturing
- Synthetic data generation for metal defect detection
- Robustness to physical variations in sensor input
- Domain adaptation for industrial computer vision

---

## ğŸ“š Citation

If you use PhysAugNet in your research, please cite:

```bibtex
@misc{parmar2025physaugnet,
  author       = {Shantanu Parmar},
  title        = {PhysAugNet: VQ-VAE and Physically-Inspired Augmentations for Metal Defect Segmentation},
  year         = {2025},
  howpublished = {\url{https://github.com/Shantanu-Parmar/PhysAugNet}},
  note         = {GitHub repository}
}
```

---

## ğŸ“„ License

**MIT License** â€” You are free to use, modify, and distribute this software with proper attribution.

Â© 2025 Shantanu Parmar. All rights reserved.
